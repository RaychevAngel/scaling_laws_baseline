# Model and dataset configuration
model_name: AngelRaychev/0.5B-policy-iteration_
revision: None
hub_model_id: AngelRaychev/0.5B-policy-iteration_
dataset_file: data/policy/iteration_
plot_path: train/logs/policy-iteration_
device: cuda

# Optimization parameters
learning_rate: 2e-6
per_device_train_batch_size: 128
per_device_eval_batch_size: 128
num_train_epochs: 5
lr_scheduler_type: "constant"
gradient_accumulation_steps: 1

# Convergence criteria
logging_steps: 10
eval_steps: 50

