# Model and dataset configuration
model_name: AngelRaychev/policy_iteration_1
device: cuda
hub_model_id: AngelRaychev/policy_iteration_2
dataset_file: data/mcts_generated/policy/policy

# Optimization parameters
learning_rate: 1e-4
lr_scheduler_type: "reduce_lr_on_plateau"
optimizer: "adamw_torch"
accumulation_steps: 2
per_device_train_batch_size: 128
max_grad_norm: 1.0

# ReduceLROnPlateau scheduler parameters
lr_scheduler_factor: 0.5
lr_scheduler_patience: 1
lr_scheduler_threshold: 0.01

# Regularization parameters
weight_decay: 0.01

# Convergence criteria
logging_steps: 5
eval_steps: 10
patience: 5
improvement_tolerance: 0.001

# Performance optimization flags
compile_model: true  # Enable torch.compile for higher GPU utilization
use_fsdp: false       # Enable FSDP for memory-efficient training
enable_profiling: false  # Enable profiling (reduces performance when true)
use_gradient_checkpointing: true  # Reduce memory usage by recomputing forward pass
