# Model and dataset configuration
model_name: AngelRaychev/0.5B-policy-iteration_
device: cuda
hub_model_id: AngelRaychev/0.5B-policy-iteration_
dataset_file: data/policy/iteration_
plot_path: train/logs/policy-iteration_

# Optimization parameters
learning_rate: 5e-5
per_device_train_batch_size: 16
num_train_epochs: 3
lr_scheduler_type: "constant"
optimizer: "adamw_torch"
accumulation_steps: 1
max_grad_norm: 1.0

# Convergence criteria
logging_steps: 10
eval_steps: 150

